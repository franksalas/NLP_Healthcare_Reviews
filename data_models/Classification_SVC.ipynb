{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory_pickle = os.path.join('..','data','pickle')\n",
    "\n",
    "dataset = os.path.join(data_directory_pickle,'health_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44918 entries, 0 to 44917\n",
      "Data columns (total 9 columns):\n",
      "business_id        44918 non-null object\n",
      "review_id          44918 non-null object\n",
      "health_business    44918 non-null object\n",
      "name               44918 non-null object\n",
      "stars              44918 non-null int64\n",
      "text               44918 non-null object\n",
      "processed          44918 non-null object\n",
      "polarity           44918 non-null float64\n",
      "subjectivity       44918 non-null float64\n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>health_business</th>\n",
       "      <th>name</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>processed</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2hpi6pXIFf0taDIYCoNIuw</td>\n",
       "      <td>4ar9LmGU4rQ3vXFj325HCg</td>\n",
       "      <td>urgent care</td>\n",
       "      <td>Healthcare Partner</td>\n",
       "      <td>1</td>\n",
       "      <td>If your aim is to waste hours upon hours of yo...</td>\n",
       "      <td>if your aim is to waste hours upon hours of yo...</td>\n",
       "      <td>-0.062605</td>\n",
       "      <td>0.532773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2hpi6pXIFf0taDIYCoNIuw</td>\n",
       "      <td>mZo59NzNBPr9RegkzjIGVA</td>\n",
       "      <td>urgent care</td>\n",
       "      <td>Healthcare Partner</td>\n",
       "      <td>5</td>\n",
       "      <td>Memorial Day Weekend..  I cannot Thank Doctor ...</td>\n",
       "      <td>memorial day weekend i cannot thank doctor shu...</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.553125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id               review_id health_business  \\\n",
       "0  2hpi6pXIFf0taDIYCoNIuw  4ar9LmGU4rQ3vXFj325HCg     urgent care   \n",
       "1  2hpi6pXIFf0taDIYCoNIuw  mZo59NzNBPr9RegkzjIGVA     urgent care   \n",
       "\n",
       "                 name  stars  \\\n",
       "0  Healthcare Partner      1   \n",
       "1  Healthcare Partner      5   \n",
       "\n",
       "                                                text  \\\n",
       "0  If your aim is to waste hours upon hours of yo...   \n",
       "1  Memorial Day Weekend..  I cannot Thank Doctor ...   \n",
       "\n",
       "                                           processed  polarity  subjectivity  \n",
       "0  if your aim is to waste hours upon hours of yo... -0.062605      0.532773  \n",
       "1  memorial day weekend i cannot thank doctor shu...  0.281250      0.553125  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.text  # \n",
    "y_s = df.stars\n",
    "y_h = df.health_business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_s, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score,recall_score,precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Define a pipeline combining\n",
    "## a text feature extractor with a simple classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LinearSVC()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "           strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "           tokenizer=None, vocabulary=None)),\n",
       "  ('tfidf',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       "  ('clf', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "        intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "        multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "        verbose=0))],\n",
       " 'vect': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=None, vocabulary=None),\n",
       " 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
       " 'clf': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "      verbose=0),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': None,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'clf__C': 1.0,\n",
       " 'clf__class_weight': None,\n",
       " 'clf__dual': True,\n",
       " 'clf__fit_intercept': True,\n",
       " 'clf__intercept_scaling': 1,\n",
       " 'clf__loss': 'squared_hinge',\n",
       " 'clf__max_iter': 1000,\n",
       " 'clf__multi_class': 'ovr',\n",
       " 'clf__penalty': 'l2',\n",
       " 'clf__random_state': None,\n",
       " 'clf__tol': 0.0001,\n",
       " 'clf__verbose': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Parameters\n",
    "\n",
    "```JSON\n",
    "{'vect__analyzer': 'word',\n",
    " 'vect__binary': False,\n",
    " 'vect__decode_error': 'strict',\n",
    " 'vect__dtype': numpy.int64,\n",
    " 'vect__encoding': 'utf-8',\n",
    " 'vect__input': 'content',\n",
    " 'vect__lowercase': True,\n",
    " 'vect__max_df': 1.0,\n",
    " 'vect__max_features': None,\n",
    " 'vect__min_df': 1,\n",
    " 'vect__ngram_range': (1, 1),\n",
    " 'vect__preprocessor': None,\n",
    " 'vect__stop_words': None,\n",
    " 'vect__strip_accents': None,\n",
    " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    " 'vect__tokenizer': None,\n",
    " 'vect__vocabulary': None,\n",
    " 'tfidf__norm': 'l2',\n",
    " 'tfidf__smooth_idf': True,\n",
    " 'tfidf__sublinear_tf': False,\n",
    " 'tfidf__use_idf': True,\n",
    " 'clf__C': 1.0,\n",
    " 'clf__class_weight': None,\n",
    " 'clf__dual': True,\n",
    " 'clf__fit_intercept': True,\n",
    " 'clf__intercept_scaling': 1,\n",
    " 'clf__loss': 'squared_hinge',\n",
    " 'clf__max_iter': 1000,\n",
    " 'clf__multi_class': 'ovr',\n",
    " 'clf__penalty': 'l2',\n",
    " 'clf__random_state': None,\n",
    " 'clf__tol': 0.0001,\n",
    " 'clf__verbose': 0}\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "            #### CountVectorizer #########\n",
    "            #'vect__analyzer':( 'word',),\n",
    "           # 'vect__binary':( False,),\n",
    "            #'vect__decode_error': ('strict',),\n",
    "            #'vect__dtype':( np.int64,),\n",
    "            #'vect__encoding':( 'utf-8',),\n",
    "            #'vect__input':( 'content',),\n",
    "            #'vect__lowercase':( True,),\n",
    "            'vect__max_df': (0.5, 0.75, 1.0), # 1.0,\n",
    "            'vect__max_features':  (None, 5000, 10000, 50000), # None,\n",
    "            'vect__min_df':(1,),\n",
    "            'vect__ngram_range':((1, 1), (1, 2)),  # unigrams or bigrams (1, 1),\n",
    "            'vect__preprocessor':( None,),\n",
    "            'vect__stop_words':( None,),\n",
    "            'vect__strip_accents': (None,),\n",
    "            'vect__token_pattern': ('(?u)\\\\b\\\\w\\\\w+\\\\b',),\n",
    "            'vect__tokenizer':( None,),\n",
    "            'vect__vocabulary':( None,),\n",
    "             #### TfidfTransformer #########\n",
    "            'tfidf__norm': ('l1', 'l2'), #'l2',\n",
    "            'tfidf__smooth_idf': (True,),\n",
    "            'tfidf__sublinear_tf':( False,),\n",
    "            'tfidf__use_idf': (True, False), # True,\n",
    "            #### Classifier : LinearSVC #########\n",
    "            'clf__C': [0.1, 1, 10, 100], # 1.0,\n",
    "            'clf__class_weight':( None,),\n",
    "            'clf__dual':( True,),\n",
    "            'clf__fit_intercept':( True,),\n",
    "            'clf__intercept_scaling':( 1,),\n",
    "            'clf__loss':( 'squared_hinge',),\n",
    "            'clf__max_iter':( 1000,),\n",
    "            'clf__multi_class':( 'ovr',),\n",
    "            'clf__penalty':( 'l2',),\n",
    "            'clf__random_state':( None,),\n",
    "            'clf__tol': (0.0001,), # 0.0001,\n",
    "            'clf__verbose': (0,),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "    GRID SEARCH ACTIVE\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "PIPELINE: ['vect', 'tfidf', 'clf']\n",
      "PARAMETERS:\n",
      "{'clf__C': [0.1, 1, 10, 100],\n",
      " 'clf__class_weight': (None,),\n",
      " 'clf__dual': (True,),\n",
      " 'clf__fit_intercept': (True,),\n",
      " 'clf__intercept_scaling': (1,),\n",
      " 'clf__loss': ('squared_hinge',),\n",
      " 'clf__max_iter': (1000,),\n",
      " 'clf__multi_class': ('ovr',),\n",
      " 'clf__penalty': ('l2',),\n",
      " 'clf__random_state': (None,),\n",
      " 'clf__tol': (0.0001,),\n",
      " 'clf__verbose': (0,),\n",
      " 'tfidf__norm': ('l1', 'l2'),\n",
      " 'tfidf__smooth_idf': (True,),\n",
      " 'tfidf__sublinear_tf': (False,),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__max_features': (None, 5000, 10000, 50000),\n",
      " 'vect__min_df': (1,),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__preprocessor': (None,),\n",
      " 'vect__stop_words': (None,),\n",
      " 'vect__strip_accents': (None,),\n",
      " 'vect__token_pattern': ('(?u)\\\\b\\\\w\\\\w+\\\\b',),\n",
      " 'vect__tokenizer': (None,),\n",
      " 'vect__vocabulary': (None,)}\n",
      "--------------------------------\n",
      "Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed: 34.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed: 74.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1768 tasks      | elapsed: 189.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1920 out of 1920 | elapsed: 218.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 13120.495s\n",
      "\n",
      "Best score: 0.812\n",
      "Best parameters set:\n",
      "\tclf__C: 1\n",
      "\tclf__class_weight: None\n",
      "\tclf__dual: True\n",
      "\tclf__fit_intercept: True\n",
      "\tclf__intercept_scaling: 1\n",
      "\tclf__loss: 'squared_hinge'\n",
      "\tclf__max_iter: 1000\n",
      "\tclf__multi_class: 'ovr'\n",
      "\tclf__penalty: 'l2'\n",
      "\tclf__random_state: None\n",
      "\tclf__tol: 0.0001\n",
      "\tclf__verbose: 0\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__smooth_idf: True\n",
      "\ttfidf__sublinear_tf: False\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: None\n",
      "\tvect__min_df: 1\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__preprocessor: None\n",
      "\tvect__stop_words: None\n",
      "\tvect__strip_accents: None\n",
      "\tvect__token_pattern: '(?u)\\\\b\\\\w\\\\w+\\\\b'\n",
      "\tvect__tokenizer: None\n",
      "\tvect__vocabulary: None\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipeline, \n",
    "                           parameters, \n",
    "                           cv=5,\n",
    "                           n_jobs=-1, \n",
    "                           verbose=1)\n",
    "print('--------------------------------')\n",
    "print(\"    GRID SEARCH ACTIVE\\n\\n\")\n",
    "print('--------------------------------')\n",
    "\n",
    "print(\"PIPELINE:\", [name for name, _ in pipeline.steps])\n",
    "print(\"PARAMETERS:\")\n",
    "pprint(parameters)\n",
    "print('--------------------------------')\n",
    "t0 = time()\n",
    "grid_search.fit(X,y_s)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## Out of the box\n",
    "```\n",
    "--------------------------------\n",
    "    GRID SEARCH ACTIVE\n",
    "\n",
    "\n",
    "--------------------------------\n",
    "PIPELINE: ['vect', 'tfidf', 'clf']\n",
    "PARAMETERS:\n",
    "{}\n",
    "--------------------------------\n",
    "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
    "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
    "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   59.8s finished\n",
    "done in 70.801s\n",
    "\n",
    "Best score: 0.788\n",
    "Best parameters set:\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "## \n",
    "\n",
    "```\n",
    "--------------------------------\n",
    "    GRID SEARCH ACTIVE\n",
    "\n",
    "\n",
    "--------------------------------\n",
    "PIPELINE: ['vect', 'tfidf', 'clf']\n",
    "PARAMETERS:\n",
    "{'clf__C': [0.1, 1, 10, 100],\n",
    " 'clf__class_weight': (None,),\n",
    " 'clf__dual': (True,),\n",
    " 'clf__fit_intercept': (True,),\n",
    " 'clf__intercept_scaling': (1,),\n",
    " 'clf__loss': ('squared_hinge',),\n",
    " 'clf__max_iter': (1000,),\n",
    " 'clf__multi_class': ('ovr',),\n",
    " 'clf__penalty': ('l2',),\n",
    " 'clf__random_state': (None,),\n",
    " 'clf__tol': (0.0001,),\n",
    " 'clf__verbose': (0,),\n",
    " 'tfidf__norm': ('l1', 'l2'),\n",
    " 'tfidf__smooth_idf': (True,),\n",
    " 'tfidf__sublinear_tf': (False,),\n",
    " 'tfidf__use_idf': (True, False),\n",
    " 'vect__max_df': (0.5, 0.75, 1.0),\n",
    " 'vect__max_features': (None, 5000, 10000, 50000),\n",
    " 'vect__min_df': (1,),\n",
    " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
    " 'vect__preprocessor': (None,),\n",
    " 'vect__stop_words': (None,),\n",
    " 'vect__strip_accents': (None,),\n",
    " 'vect__token_pattern': ('(?u)\\\\b\\\\w\\\\w+\\\\b',),\n",
    " 'vect__tokenizer': (None,),\n",
    " 'vect__vocabulary': (None,)}\n",
    "--------------------------------\n",
    "Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n",
    "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
    "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  2.7min\n",
    "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  8.6min\n",
    "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed: 18.7min\n",
    "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed: 34.9min\n",
    "[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed: 74.5min\n",
    "[Parallel(n_jobs=-1)]: Done 1768 tasks      | elapsed: 189.1min\n",
    "[Parallel(n_jobs=-1)]: Done 1920 out of 1920 | elapsed: 218.0min finished\n",
    "done in 13120.495s\n",
    "\n",
    "Best score: 0.812\n",
    "Best parameters set:\n",
    "\tclf__C: 1\n",
    "\tclf__class_weight: None\n",
    "\tclf__dual: True\n",
    "\tclf__fit_intercept: True\n",
    "\tclf__intercept_scaling: 1\n",
    "\tclf__loss: 'squared_hinge'\n",
    "\tclf__max_iter: 1000\n",
    "\tclf__multi_class: 'ovr'\n",
    "\tclf__penalty: 'l2'\n",
    "\tclf__random_state: None\n",
    "\tclf__tol: 0.0001\n",
    "\tclf__verbose: 0\n",
    "\ttfidf__norm: 'l2'\n",
    "\ttfidf__smooth_idf: True\n",
    "\ttfidf__sublinear_tf: False\n",
    "\ttfidf__use_idf: True\n",
    "\tvect__max_df: 0.5\n",
    "\tvect__max_features: None\n",
    "\tvect__min_df: 1\n",
    "\tvect__ngram_range: (1, 2)\n",
    "\tvect__preprocessor: None\n",
    "\tvect__stop_words: None\n",
    "\tvect__strip_accents: None\n",
    "\tvect__token_pattern: '(?u)\\\\b\\\\w\\\\w+\\\\b'\n",
    "\tvect__tokenizer: None\n",
    "\tvect__vocabulary: None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.756\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "svc_count_clf = LinearSVC()\n",
    "svc_count_clf.fit(count_train, y_train)\n",
    "pred = svc_count_clf.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.827\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2),max_df=0.5,)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "svc_tfidf_clf = LinearSVC()\n",
    "svc_tfidf_clf.fit(tfidf_train, y_train)\n",
    "pred = svc_tfidf_clf.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
